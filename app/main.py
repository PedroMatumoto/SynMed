import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer


@st.cache_resource
def load_model():
    return SentenceTransformer("multi-qa-mpnet-base-cos-v1")

@st.cache_resource
def load_llm():
    model_id = "openai/gpt-oss-20b"
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype="auto", device_map="auto")
    return tokenizer, model

tokenizer, model = load_llm()
sentence_model = load_model()

def extract_symptoms(text):
    prompt = f"Voc√™ √© um extrator de sintomas. Extraia os sintomas do seguinte texto: {text}"
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    output = model.generate(**inputs, max_new_tokens=50)
    texto = tokenizer.decode(output[0], skip_special_tokens=True)
    return texto.split("Sintomas:")[-1].strip()

data = {
    "Rem√©dios": [
        "Paracetamol",
        "Ibuprofeno",
        "Dipirona",
        "Antihistam√≠nicos"
    ],
    "Sintomas": [
        "dor no corpo",
        "tosse seca",
        "dor de cabe√ßa intensa",
        "espirros"
    ]
}
df = pd.DataFrame(data)
print(df)

df["embedding"] = df["Sintomas"].apply(lambda x: sentence_model.encode(x, convert_to_tensor=True))

st.title("üîé Diagn√≥stico por Similaridade Sem√¢ntica")

chat = st.chat_message("human")
chat.subheader("Ol√°! Eu sou o SynMed, seu assistente de sa√∫de.")
chat.write("Digite os sintomas que voc√™ est√° sentindo:")

sintomas_usuario = chat.text_area(
    label="Input", 
    label_visibility="hidden", 
    placeholder="Ex: dor de cabe√ßa, febre, tosse seca"
)

if st.button("Buscar"):
    if sintomas_usuario.strip() != "":
        with st.spinner("Processando com gpt-oss-20b..."):
            sintomas_extraidos = extract_symptoms(sintomas_usuario)
        chat = st.chat_message("assistant")
        chat.subheader("Sintomas extra√≠dos:")
        chat.write(sintomas_extraidos)
        query_emb = sentence_model.encode(sintomas_extraidos, convert_to_tensor=True)

        scores = [util.cos_sim(query_emb, emb).item() for emb in df["embedding"]]
        df["similaridade"] = scores

        resultados = df.sort_values("similaridade", ascending=False).head(3)

        chat.subheader("Resultados mais semelhantes:")
        for _, row in resultados.iterrows():
            chat.write(f"**Doen√ßa:** {row['Doenca']}")
            chat.write(f"**Sintomas cadastrados:** {row['Sintomas']}")
            chat.write(f"**Similaridade:** {row['similaridade']:.2f}")
            chat.markdown("---")

        with st.spinner("Consultando a LLM para recomenda√ß√µes..."):
            top_remedio = resultados.iloc[0]["Rem√©dios"]
            prompt = f"Monte uma resposta amig√°vel para o usu√°rio, recomendando o rem√©dio '{top_remedio}' com base nos sintomas '{sintomas_extraidos}'."
            inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
            output = model.generate(**inputs, max_new_tokens=100)
            resposta = tokenizer.decode(output[0], skip_special_tokens=True)
            chat = st.chat_message("assistant")
            chat.subheader("Resposta da LLM:")
            chat.write(resposta)
    else:
        st.warning("Por favor, digite os sintomas antes de buscar.")
